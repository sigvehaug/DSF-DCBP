{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/DSF-DCBP/blob/main/02_Intro_Pandas_Numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a_Gy0cT_da8"
      },
      "source": [
        "# Pandas and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Why Pandas and NumPy?\n",
        "\n",
        "Python has built-in data structures like lists and dictionaries, but they are not optimized for fast computation on large numerical tables. Two libraries fill this gap:\n",
        "\n",
        "* **NumPy** provides fast *arrays* and numerical operations.\n",
        "* **Pandas** provides higher-level tabular structures such as the **DataFrame**, built on top of NumPy.\n",
        "\n",
        "In this notebook we will:\n",
        "\n",
        "1. Load the polymer dataset (`train.csv`) from this [Kaggle competition](https://www.kaggle.com/competitions/neurips-open-polymer-prediction-2025/data) into a Pandas DataFrame\n",
        "2. Inspect its structure and data types\n",
        "3. Handle missing values\n",
        "4. Compute simple summary statistics\n",
        "5. Create basic visualizations\n",
        "6. Peek under the hood: Pandas columns are NumPy arrays\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Loading the dataset\n",
        "\n",
        "1. Download the data from the [Ilias page](https://ilias.unibe.ch/ilias.php?baseClass=ilrepositorygui&cmdNode=zo:ok&cmdClass=ilObjFileGUI&cmd=sendfile&ref_id=3663532).\n",
        "2. Extract all files into a 'data' folder. Where you place the folder is important and changes its path!\n",
        "\n",
        "### Option A — Load from local file\n",
        "\n",
        "1. Upload it to your notebook environment\n",
        "2. Use:\n",
        "\n",
        "```python\n",
        "# Adjust path if needed (e.g., \"/data/train.csv\" in Colab)\n",
        "path = \"data/train.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df.head()\n",
        "```\n",
        "\n",
        "### Option B — Load on Google Colab\n",
        "\n",
        "```python\n",
        "import os\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    path = \"/content/drive/MyDrive/DSF-DCBP/data/train.csv\"  # adjust based on your file location in Google Drive\n",
        "    df = pd.read_csv(path)\n",
        "    df.head()\n",
        "except ImportError:\n",
        "    print(\"Not running on Colab, load from local file system.\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. First look: what did we load?\n",
        "\n",
        "```python\n",
        "type(df)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A Pandas **DataFrame** is a 2D table with:\n",
        "\n",
        "* rows (observations)\n",
        "* columns (variables)\n",
        "* an index (row labels)\n",
        "\n",
        "Show shape (rows, columns):\n",
        "\n",
        "```python\n",
        "df.shape\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show column names:\n",
        "\n",
        "```python\n",
        "df.columns\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Dataset documentation (columns)\n",
        "\n",
        "Each row corresponds to a polymer structure (as a SMILES string) with several target properties.\n",
        "\n",
        "* `id`: unique identifier\n",
        "* `SMILES`: polymer repeating unit encoded as text (SMILES)\n",
        "* `Tg`: glass transition temperature (°C)\n",
        "* `FFV`: fractional free volume\n",
        "* `Tc`: thermal conductivity (W / m·K)\n",
        "* `Density`: density (scaled; your note says `g·cm⁻3 × 10⁻3`)\n",
        "* `Rg`: radius of gyration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Data types and missing values\n",
        "\n",
        "### DataFrame overview\n",
        "\n",
        "```python\n",
        "df.info()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Key things to notice:\n",
        "\n",
        "* Which columns are numeric?\n",
        "* Which are text?\n",
        "* How many missing values per column?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count missing values explicitly\n",
        "\n",
        "```python\n",
        "df.isna().sum() # if you want to also sort them: .sort_values(ascending=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Basic statistics (numeric columns)\n",
        "\n",
        "```python\n",
        "df.describe()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Accessing columns\n",
        "\n",
        "Extract a single column (Series):\n",
        "\n",
        "```python\n",
        "tc = df[\"Tc\"]\n",
        "type(tc), tc.head()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract multiple columns (DataFrame):\n",
        "\n",
        "```python\n",
        "targets = df[[\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]]\n",
        "targets.head()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 9. Under the hood: Pandas uses NumPy arrays\n",
        "\n",
        "A Pandas Series stores its values in a NumPy array:\n",
        "\n",
        "```python\n",
        "tc_values = df[\"Tc\"].values\n",
        "type(tc_values), tc_values[:10]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 10. Cleaning: select rows with at least one target available\n",
        "\n",
        "In this dataset, many targets are missing for many rows. It’s useful to select rows with at least one property measured.\n",
        "\n",
        "```python\n",
        "target_cols = [\"Tg\", \"FFV\", \"Tc\", \"Density\", \"Rg\"]\n",
        "\n",
        "df_any_target = df.dropna(subset=target_cols, how=\"all\") # drop only if 'all' values in those column are missing\n",
        "df_any_target.shape\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also useful: rows with **all targets present**:\n",
        "\n",
        "```python\n",
        "df_all_targets = df.dropna(subset=target_cols, how=\"any\") #  if 'any' of the values in those columns are missing, drop that row\n",
        "df_all_targets.shape\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 11. Simple feature engineering from SMILES\n",
        "\n",
        "We can compute simple text-based features:\n",
        "\n",
        "* SMILES length\n",
        "\n",
        "```python\n",
        "df[\"smiles_len\"] = df[\"SMILES\"].astype(str).str.len()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or more complex features:\n",
        "* count of specific characters (rings, branches, aromatic atoms)\n",
        "\n",
        "```python\n",
        "df[\"count_aromatic_c\"] = df[\"SMILES\"].astype(str).str.count(\"c\")\n",
        "df[\"count_branch\"] = df[\"SMILES\"].astype(str).str.count(r\"\\(\")\n",
        "df[\"count_ring_digits\"] = df[\"SMILES\"].astype(str).str.count(r\"[0-9]\")\n",
        "df[\"count_star\"] = df[\"SMILES\"].astype(str).str.count(r\"\\*\")\n",
        "\n",
        "df[[\"SMILES\", \"smiles_len\", \"count_aromatic_c\", \"count_branch\", \"count_ring_digits\", \"count_star\"]].head()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0EVprp7euN1"
      },
      "source": [
        "# Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Iosdk-tYtsd"
      },
      "source": [
        "1. In the Data folder on Ilias there is an additional folder called 'train_supplement'. Choose one of the datasets in there.\n",
        "    * If you use Google Colab, upload that file to a folder on your google drive. If you don't have a google account, make it now.\n",
        "    * If you are working locally, download it and find its path.\n",
        "    Look at the file by clicking on it. Does it contain the same columns of the 'train.csv' dataset?\n",
        "\n",
        "2. Load the dataset as we did before for the 'train.csv' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYR4iYYhI0gH",
        "outputId": "5d49ecb7-fb5d-44d9-fceb-8652da4039b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-hJAIi5R69m"
      },
      "source": [
        "3. Study this dataset a bit with df.info() and df.describe() methods. How big is the dataset: How many rows, how many columns, how much space in the memory?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "mJ1eSjLTAB7n",
        "outputId": "b26a4c54-549f-4e57-c5bf-d975c35d6041"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Which column has the most missing values among the targets, if any?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HjPQjXGS74M"
      },
      "source": [
        "5. Plot some columns with an histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Bo0523KXPuUO",
        "outputId": "b7ab658f-93e1-405c-f909-340ec847406f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Takeaways\n",
        "\n",
        "* Pandas DataFrames are the standard for tabular data in Python.\n",
        "* Columns are backed by NumPy arrays, enabling fast computations.\n",
        "* Real datasets have missing values: you must inspect and handle them.\n",
        "* You can create useful numeric features from currently existing ones."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "02-Intro_Pandas_Numpy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "general",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
