{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-Numpy_arrays.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/DSF-DCBP/blob/main/05_Numpy_arrays.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LZWsXsoP9xF"
      },
      "source": [
        "This notebook has been provided by G. Witz, University of Bern\n",
        "\n",
        "# 5. Numpy arrays\n",
        "\n",
        "We have seen in a previous notebook that the objects underlying the complex DataFrames are Numpy arrays. Why do we need this additional container and why can't we just use Python lists ?\n",
        "\n",
        "Let's imagine we have a list containing weights in gramms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iY_ZQgrTWCa"
      },
      "source": [
        "#gramms = [5400, 3491, 2591, 14100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvPLOmlMTxbY"
      },
      "source": [
        "Now we want to transform this list into kilogramms. We don't have any other choice than using a for loop (or a comprehension list) to divide each element by 1000:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nK4mxwlT7ys"
      },
      "source": [
        "# kilogramms = []\n",
        "# for i in range(len(gramms)):\n",
        "#   new_value = gramms[i]/1000\n",
        "#   kilogramms.append(new_value)\n",
        "# kilogramms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RleZZQejUI1c"
      },
      "source": [
        "You can imagine much more complex cases, e.g. where we mix multiple lists, that makes this writing cumbersome and slow. What arrays provide us is **vectorized** computations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPNdTPiiTT3A"
      },
      "source": [
        "## Creating an array\n",
        "\n",
        "To see how this works , let's create a Numpy array (without extracting it from a DataFrame). First of all, let's import Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNYiEOyUaQD"
      },
      "source": [
        "# import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aPAQuXVUxRl"
      },
      "source": [
        "We can easily turn our previous list into an array using the ```np.array``` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50BgLjoRU4YZ"
      },
      "source": [
        "# gramms_array = np.array(gramms)\n",
        "# gramms_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nMaz-_DVBhM"
      },
      "source": [
        "**Vectorization** means now that we can operate on the list as **one object**, i.e. we can do mathematics with it as with a single number. In our example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG3ZfpPdVNzG"
      },
      "source": [
        "# kilogramms_array = gramms_array / 1000\n",
        "# kilogramms_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Bl_00LS9ns"
      },
      "source": [
        "As mentioned above, this also works if we need to performe a computation which uses multiple arrays. Let's imagine we have a list of price/$m^2$ and surface for a series of appartments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63RxqWJCSj6Q"
      },
      "source": [
        "# price_per_m2 = [6, 10.3, 12.4, 10.6, 5.7, 4.3, 14, 0.5, 0.5, 17.8, 12.7, 16, 2.7, 17.5, 5.2, 7.1, 1.2, 7.2, 14.5, 11.9]\n",
        "# surface = [238, 239, 265, 212, 143, 132, 142, 133, 109, 291, 225, 165, 141, 197, 298, 289, 123,  90, 132, 203]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kONcD-Fo-AzN"
      },
      "source": [
        "Now if we want to calculate the price of the apartment, we can just multiply each price/$m^2$ by the surface. We can do that by creating a for loop and filling a new list with the values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2mXTvba-VSH"
      },
      "source": [
        "# price = []\n",
        "# for i in range(len(price_per_m2)):\n",
        "#   current_price = price_per_m2[i] * surface[i]\n",
        "#   price.append(current_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18M7PDlS-WPA"
      },
      "source": [
        "# price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehykz3OdTGog"
      },
      "source": [
        "Again we transform the two lists into arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EuNCAor-aZx"
      },
      "source": [
        "# price_per_m2_array = np.array(price_per_m2)\n",
        "# surface_array = np.array(surface)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlUpfLap-nqy"
      },
      "source": [
        "Instead of having to write a foor loop, Numpy allows us now to just use a standard mathemetical operation where we multiply the two arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ThA10V8UTop"
      },
      "source": [
        "# price_array = price_per_m2_array * surface_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0czFHhOsUhZx"
      },
      "source": [
        "# price_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McdhU9iXUuuA"
      },
      "source": [
        "You see that when multiplying two arrays, **Numpy simply multiplies each element of one array by the equivalent element of the other array**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hpAJQGzWaVW"
      },
      "source": [
        "## Advantages of vectorization\n",
        "There are two main advantages to this approach. First it makes the code much **simpler**: we achieved in a single line, what took an entire for loop with simples lists (there are slightly more efficient ways to do that even in plain Python via comprehension lists).\n",
        "\n",
        "Second, it makes our code run much **faster**. When we do a for loop, each operation is done separately, and since Python is dynamically typed (you don't have to say whether a variable is text or numbers) it has to repeatedly carry out verifications. In the Numpy vectorized version, all multiplications can be done **in parallel** because: 1) the array contains only one type of variables so that no controls have to be done and 2) arrays are efficiently stored as blocks in memory so that individual values don't have to be \"searched\" for.\n",
        "\n",
        "With this very simple example, we can compare the execution time using the magic command ```%%timeit```:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTiAVpCKUjJx"
      },
      "source": [
        "# %%timeit -n 10000 -r 5 \n",
        "# price = []\n",
        "# for i in range(len(price_per_m2)):\n",
        "#   current_price = price_per_m2[i] * surface[i]\n",
        "#   price.append(current_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fviMiCFSU976"
      },
      "source": [
        "# %%timeit -n 10000 -r 5\n",
        "# price_array = price_per_m2_array * surface_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyJZzn1cV0q9"
      },
      "source": [
        "## Array type\n",
        "\n",
        "We have mentioned above that computation is fast because the type of the arrays is known. This means that **all the elements of an array** must have the same type. Numpy implements its own types called ```dtype```. We can access to the type of an array using this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MuC_434EtE1"
      },
      "source": [
        "# price_per_m2_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOhyeVexVF2m"
      },
      "source": [
        "# price_per_m2_array.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGthedPBBH4u"
      },
      "source": [
        "We see that by default Numpy decided that the price had ```float64``` dtype because the numbers we used had a comma. Notice it also turned the numbers that **didn't** have a comma into floats (like the first element ```6```). Since all elements of an array need to have the same type, Numpy just selects the **most complex one** for the entire array.\n",
        "\n",
        "Let's see what ```dtype``` the surface array has:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiTip4BVDp7G"
      },
      "source": [
        "# surface_array.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeBmGsjVD14p"
      },
      "source": [
        "We **only** used integerer numbers in that list, and therefore Numpy can use a \"simpler\" ```dtype``` for that array.\n",
        "\n",
        "Finally let's see the result of our multiplication:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we6JrGvREPpi"
      },
      "source": [
        "# price_array.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jaZBMNHFaJ7"
      },
      "source": [
        "When combining multiple arrays, Numpy always **selects** the most complex ```dtype``` for the output.\n",
        "\n",
        "If needed we can also change the ```dtype``` of an array explicitly using the ```as_type``` method. For example if we want our ```surface_array``` to be a float instead of an integer we can write:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTBNNZ0VF3CS"
      },
      "source": [
        "# surface_array_float = surface_array.astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO6U9vkYF8nR"
      },
      "source": [
        "surface_array_float.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncEzbShkF994"
      },
      "source": [
        "Notice how we had to create a **new** array: most operations on Numpy arrays are **not done in place** i.e. the array itsels is not changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Szx8kPgGJnj"
      },
      "source": [
        "## Back to Pandas\n",
        "\n",
        "Before we explore a bit further Numpy arrays and the operations we can apply on them, let's briefly come back to our Pandas DataFrame. We will use a simpler table that is also available online [here](https://github.com/guiwitz/NumpyPandas_course/blob/master/Data/composers.xlsx). Notice that this is this time really an Excel sheet, so we use the ```read_excel``` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxVbpQBGelD"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# composers = pd.read_excel('https://github.com/guiwitz/NumpyPandas_course/blob/master/Data/composers.xlsx?raw=true')\n",
        "# composers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRAjPJXbGjuf"
      },
      "source": [
        "Let's look at the birth column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc2RRRfMGms2"
      },
      "source": [
        "# composers['birth']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2bTOoyHUPI1"
      },
      "source": [
        "We see that we here also get a ```dtype``` information, in this case int64, since the underlying data of the DataFrame are Numpy arrays.\n",
        "\n",
        "Just like with Numpy arrays, we can explicitely ask for the ```dtype```:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiBUIB3cUhM2"
      },
      "source": [
        "# composers['birth'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fElNvuoUvIU"
      },
      "source": [
        "And we can also change the ```dtype``` using ```astype()```. Here again, we need to **asign** the resulto the change to a new series or directly to the original DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2CMoICU7Nb"
      },
      "source": [
        "# composers['birth'] = composers['birth'].astype(np.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnVDVvD5VMe-"
      },
      "source": [
        "# composers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7I0AtNVNSU"
      },
      "source": [
        "# composers['birth'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDNlZy9oVP1p"
      },
      "source": [
        "We immediately see that the numbers in the ```birth``` column have now a comma, and if we ask for the column type, we indeed get now a float."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6qT3vkSVaFi"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "1. Create an array with 3 elements and one with 5 elements containing integers\n",
        "2. Try to multiply the two arrays.\n",
        "3. You should get an error message. Do you understand the problem ? How can you fix it?\n",
        "4. Change the ```dtype``` of the output to float32.\n",
        "5. Import the file that you cand find here: https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\n",
        "6. Use ```head()``` to visualize a few lines\n",
        "7. What's the type of the ```body_mass_g``` and ```year``` columns ?\n",
        "8. Transform the type of the ```year``` column into a float"
      ]
    }
  ]
}