{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/DSF-DCBP/blob/main/12_Fitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 Fitting"
      ],
      "metadata": {
        "id": "bGCDbjCaQKQh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr1UJ8ccpOj2"
      },
      "source": [
        "In science we develop and create models which sometimes also become theories. Models normally contain adjustable parameteres. Such parameters can be determined from data. This task is called parameter fitting.\n",
        "\n",
        "In chemical models there are parameters which have been obtained, i.e. fitted from data. Several Python modules, e.g. the stats, the optimize or the symfit modules, have fitting methods. In this notebook we look at some of them.\n",
        "\n",
        "When fitting data, we do optimisation, i.e. we find some minimum of a function depending on our parameters. This normally include derivatives with respect to the parameters and some optimisation function. Much used optimisation functions are\n",
        "- Maximum Likelihood\n",
        "- Least Squares\n",
        "\n",
        "In Machine Learning or Artificial Intelligence we do the same. We fit parameters, up to trillions, of the model to data. In this field, the function to be optimized is called Loss or Cost function. The loss function is often a least squares.\n",
        "\n",
        "When you fit parameters, you are often confronted with (at least) three issues.\n",
        "- Goodness of Fit\n",
        "- Overfitting\n",
        "- Local or global minimum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19ZOClUOpp8N"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting data with stats PDFs"
      ],
      "metadata": {
        "id": "Lr6csTp-8GyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scipy.stats module has many probability density functions which can be used to describe and model data. Let us fit some of the MCR data to gaussian distributions, i.e. normal models."
      ],
      "metadata": {
        "id": "SVukJ6-e8S4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Courses/DSF-DCBP/Data-MCR/P3HT_Abs_data_Teaching.txt' #Data-CCD/4ms_10 av_30 s_Absorbance_10-32-04-868.txt'"
      ],
      "metadata": {
        "id": "PsDuE81s-mGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "````\n",
        "# Read the MCR data into a dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv(path, delimiter='\\t',header=0)\n",
        "df.info()````\n"
      ],
      "metadata": {
        "id": "wYclrrssay4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(path, delimiter='\\t', header=0)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "Fa69poJB_eoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```df.head()```"
      ],
      "metadata": {
        "id": "buC5ba3NbIsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "mHyT0bZLON5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# Histogram of selected columns\n",
        "df.hist(df.columns[5], bins=20)\n",
        "```\n"
      ],
      "metadata": {
        "id": "DazOENgbbVuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(df.columns[5], bins=30)"
      ],
      "metadata": {
        "id": "lFVCbH5V5qR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:,5]"
      ],
      "metadata": {
        "id": "GWny3HeLWg4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "norm.fit(df.iloc[:,5].dropna())"
      ],
      "metadata": {
        "id": "Fa5GS9VN0P-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predefined pdfs in scipy.stats you can see https://docs.scipy.org/doc/scipy/reference/stats.html. Sometimes you want to define your own model, or it is not already implemented, or you don't find the implementation. Then you can write your own model and use the scipy.optimize modul."
      ],
      "metadata": {
        "id": "E3CceVysMBBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting your own model with scipy.optimize"
      ],
      "metadata": {
        "id": "O3oss-t--5PF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's practice with scipy.optimize. First we generate syntetic data from an exponential funciton with three parameters. Then we add gaussian noise to the data so that it becomes more realistic. Lastly we fit the parameters of a self-defined exponential function to that noisy data.  "
      ],
      "metadata": {
        "id": "WOXR45QOAWYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def func(x, a, b, c):\n",
        "     return a * np.exp(-b * x) + c\n",
        "\n",
        "xdata = np.linspace(0, 4, 50) #\n",
        "y = func(xdata, 2.5, 1.3, 0.5)\n",
        "plt.plot(xdata, y, 'g-', label='Generated data')\n",
        "np.random.seed(1729)\n",
        "y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
        "ydata = y + y_noise\n",
        "plt.plot(xdata, ydata, 'b-', label='Generated data with noise')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```"
      ],
      "metadata": {
        "id": "pMPvoRvzGJIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "def func(x, a, b, c):\n",
        "  return a * np.exp(-b*x) + c\n",
        "\n",
        "xdata = np.linspace(0,4,50)\n",
        "y = func(xdata, 2.5, 1.3, 0.5)\n",
        "plt.plot(xdata, y, 'g-', label='Generated data')\n",
        "\n",
        "np.random.seed(1729)\n",
        "y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
        "ydata = y + y_noise\n",
        "\n",
        "plt.plot(xdata, ydata, 'b-', label='Generated data with noise')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MP76NqIMnawm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tN4leaPmydp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dV2kvCOhydj0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "popt, pcov = curve_fit(func, xdata, ydata)\n",
        "print(popt)\n",
        "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
        "plt.plot(xdata, func(xdata, *popt), 'r-',label= \\\n",
        "         'fit: a=%5.3f +- %5.3f, \\n b=%5.3f +- %5.3f, \\n c=%5.3f +-%5.3f' % \\\n",
        "         (popt[0],perr[0],popt[1],perr[1],popt[2],perr[2]))\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.plot(xdata, ydata, 'b+', label='Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
        "perr\n",
        "```"
      ],
      "metadata": {
        "id": "QSRzkX2xGUjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "popt,pcov = curve_fit(func, xdata, ydata)\n",
        "print(popt)\n",
        "print(pcov)\n",
        "perr = np.sqrt(np.diag(pcov))\n",
        "print(perr)"
      ],
      "metadata": {
        "id": "OUcHYnBynfr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(xdata, func(xdata, *popt), 'r-',label= \\\n",
        "         'fit: a=%5.3f +- %5.3f, \\n b=%5.3f +- %5.3f, \\n c=%5.3f +-%5.3f' % \\\n",
        "         (popt[0],perr[0],popt[1],perr[1],popt[2],perr[2]))\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.plot(xdata, ydata, 'b+', label='Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
        "perr"
      ],
      "metadata": {
        "id": "bWfxcuCg14IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So with scipy.optimize you can define your own function/model and fit its parameters to your data. There exist other libraries which makes fitting even more convenient. In the next section we look at one."
      ],
      "metadata": {
        "id": "xOaPwHTgBPqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting with symfit"
      ],
      "metadata": {
        "id": "LHQHnb_Hnwie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The more comprehensive module for fitting with Python is symfit (https://symfit.readthedocs.io/). By reading it's documentation, you can also learn very compactly the most important things about fitting. Let us do a short tutorial here.\n"
      ],
      "metadata": {
        "id": "HOjHlDK_n6u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install symfit"
      ],
      "metadata": {
        "id": "vvqmwQrCuaMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from symfit import Parameter, Variable, parameters\n",
        "\n",
        "a = Parameter('a')\n",
        "b = Parameter('b')\n",
        "x = Variable('x')\n",
        "model = a * x + b"
      ],
      "metadata": {
        "id": "abhg3f7vzJYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from symfit import Fit\n",
        "import numpy as np\n",
        "\n",
        "xdata = np.linspace(0, 100, 100) # From 0 to 100 in 100 steps\n",
        "a_vec = np.random.normal(15.0, scale=2.0, size=(100,))\n",
        "b_vec = np.random.normal(100.0, scale=2.0, size=(100,))\n",
        "ydata = a_vec * xdata + b_vec\n",
        "\n",
        "fit = Fit(model, xdata, ydata)\n",
        "fit_result = fit.execute()\n",
        "fit_result.minimizer_output"
      ],
      "metadata": {
        "id": "6xUzwnrZzmn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_result.value(a)"
      ],
      "metadata": {
        "id": "mmauLgEDz5IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voluntary Exercise\n",
        "\n",
        "If you have time and interest, study and play with the notebook provided by the [FemtoMat](https://banerji.dcbp.unibe.ch/) group.\n",
        "- https://github.com/sigvehaug/DSF-DCBP/blob/60f69ef96a4c394f6df5030259f6ea99ddbdc4b2/Fitting_Example.ipynb"
      ],
      "metadata": {
        "id": "den2VClzRCT5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFSP0Is1RKda"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "12-Fitting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}